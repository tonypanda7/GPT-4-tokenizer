{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8a3c31-9aee-4c99-9860-a313cdf666fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6964b38c-2223-4c54-986b-474b16f009c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_TOKENS = {\n",
    "    \"<|bos|>\": 100000,\n",
    "    \"<|eos|>\": 100001,\n",
    "    \"<|endoftext|>\": 100002,\n",
    "}\n",
    "\n",
    "Special_token_id={v:k for k,v in SPECIAL_TOKENS.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fe78970-a1d2-4b2c-9434-4d410db929ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_Pattern=re.compile(r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\")\n",
    "def find_patterns(text):\n",
    "    return NE_Pattern.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81b75e45-c4bc-4e3b-b723-56ef3535ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_pattern=re.compile(\"(\" + \"|\".join(re.escape(t) for t in SPECIAL_TOKENS) + \")\")\n",
    "def find_special_pattern(text):\n",
    "    return special_pattern.split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cfd5510-2bf6-4a80-b4dc-88ee564ae9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids):\n",
    "    count={}\n",
    "    for pair in zip(ids,ids[1:]):\n",
    "        count[pair]=count.get(pair,0)+1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f26b8adf-2b7a-493b-9f2e-eea31ec825ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_arr(arr,pair,idx):\n",
    "    new_arr=[]\n",
    "    i=0\n",
    "    while(i<len(arr)):\n",
    "        if i < len(arr)-1 and arr[i]==pair[0] and arr[i+1]==pair[1]:\n",
    "            new_arr.append(idx)\n",
    "            i+=2\n",
    "        else :\n",
    "            new_arr.append(arr[i])\n",
    "            i+=1\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9c8f65b-cdb6-402e-bd82-42d088177e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe(corpus,vocab_size=100000):\n",
    "    ids=[]\n",
    "    for text in corpus:\n",
    "        for part in find_special_pattern(text):\n",
    "            if part in SPECIAL_TOKENS:\n",
    "                continue\n",
    "            else:\n",
    "                for small_part in find_patterns(part):\n",
    "                    ids.extend(small_part.encode(\"utf-8\"))\n",
    "    merges={}\n",
    "    next_id=256\n",
    "    while(next_id<vocab_size):\n",
    "        stats=get_stats(ids)\n",
    "        if not stats:\n",
    "            break\n",
    "        pair = max(stats,key=stats.get)\n",
    "        merges[pair]=next_id\n",
    "        ids=merge(ids,pair,next_id)\n",
    "        next_id+=1\n",
    "\n",
    "        if next_id%1000==0:\n",
    "            print(f\"trained vocab size: {next_id}\")\n",
    "    return merges\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f81e3f8-7f94-4a7a-a6ab-17e0f05fee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(merges):\n",
    "    vocab={idx:bytes([idx]) for idx in range(256)}\n",
    "    for (p0,p1),idx in merges.items():\n",
    "        vocab[idx]=vocab[p0]+vocab[p1]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d026ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "\" hello world ! \",\n",
    "\" hello world ? \",\n",
    "\" hello there ! \",\n",
    "\" hello again , world . \",\n",
    "\" what is your name ? \",\n",
    "\" how does this work ? \",\n",
    "\" why is tokenization important ? \",\n",
    "\" can machines understand language ? \",\n",
    "\" yes , they can learn patterns . \",\n",
    "\" this is a simple example . \",\n",
    "\n",
    "\" numbers like 123 and 456 appear often . \",\n",
    "\" floating point values like 3.14 are common . \",\n",
    "\" percentages like 50 % and 100 % exist . \",\n",
    "\" dates like 2024 - 01 - 01 are used . \",\n",
    "\" time formats like 10 : 30 am appear . \",\n",
    "\" phone numbers like 123 - 456 - 7890 exist . \",\n",
    "\" currency values include $ 100 , € 50 , ₹ 500 . \",\n",
    "\" math expressions like 5 + 3 = 8 work . \",\n",
    "\" equations such as x = y + z appear . \",\n",
    "\" brackets ( ) [ ] { } are symbols . \",\n",
    "\n",
    "\" punctuation includes commas , periods . and semicolons ; \",\n",
    "\" question marks ? and exclamation marks ! matter . \",\n",
    "\" quotes like \\\" hello \\\" and ' world ' appear . \",\n",
    "\" ellipsis ... is also punctuation . \",\n",
    "\" dashes - and underscores _ exist . \",\n",
    "\" special characters @ # $ % ^ & * appear . \",\n",
    "\" slashes / and backslashes \\\\ are used . \",\n",
    "\" pipes | and colons : appear . \",\n",
    "\" comparison operators < > <= >= == != exist . \",\n",
    "\" logical operators && || ! appear . \",\n",
    "\n",
    "\" programming languages include python , java , and c ++ . \",\n",
    "\" python code uses indentation . \",\n",
    "\" loops like for i in range ( 10 ) run . \",\n",
    "\" conditionals use if else statements . \",\n",
    "\" functions return values . \",\n",
    "\" variables store data . \",\n",
    "\" arrays store multiple values . \",\n",
    "\" dictionaries map keys to values . \",\n",
    "\" classes define objects . \",\n",
    "\" methods belong to classes . \",\n",
    "\n",
    "\" machine learning is a subset of ai . \",\n",
    "\" deep learning uses neural networks . \",\n",
    "\" transformers use attention mechanisms . \",\n",
    "\" training involves optimizing weights . \",\n",
    "\" loss functions measure error . \",\n",
    "\" gradients update parameters . \",\n",
    "\" backpropagation computes gradients . \",\n",
    "\" datasets contain many samples . \",\n",
    "\" validation checks performance . \",\n",
    "\" testing evaluates models . \",\n",
    "\n",
    "\" data science combines statistics and coding . \",\n",
    "\" probability theory is important . \",\n",
    "\" random variables follow distributions . \",\n",
    "\" mean , median , and mode are statistics . \",\n",
    "\" variance measures spread . \",\n",
    "\" correlation indicates relationships . \",\n",
    "\" visualization helps understanding . \",\n",
    "\" charts include bar , line , and pie . \",\n",
    "\" dashboards summarize information . \",\n",
    "\" reports communicate results . \",\n",
    "\n",
    "\" web development includes frontend and backend . \",\n",
    "\" html , css , and javascript are used . \",\n",
    "\" apis connect systems . \",\n",
    "\" requests use http methods . \",\n",
    "\" responses include status codes . \",\n",
    "\" servers handle traffic . \",\n",
    "\" databases store persistent data . \",\n",
    "\" sql queries retrieve rows . \",\n",
    "\" nosql systems scale horizontally . \",\n",
    "\" caching improves speed . \",\n",
    "\n",
    "\" cloud computing enables scalability . \",\n",
    "\" distributed systems handle failures . \",\n",
    "\" concurrency allows parallel execution . \",\n",
    "\" threads share memory . \",\n",
    "\" processes isolate execution . \",\n",
    "\" synchronization avoids race conditions . \",\n",
    "\" locks control access . \",\n",
    "\" deadlocks must be avoided . \",\n",
    "\" performance optimization matters . \",\n",
    "\" monitoring tracks metrics . \",\n",
    "\n",
    "\" cybersecurity protects systems . \",\n",
    "\" encryption secures communication . \",\n",
    "\" hashing stores passwords . \",\n",
    "\" authentication verifies identity . \",\n",
    "\" authorization controls access . \",\n",
    "\" vulnerabilities can be exploited . \",\n",
    "\" patches fix security issues . \",\n",
    "\" firewalls filter traffic . \",\n",
    "\" attacks include phishing and malware . \",\n",
    "\" secure coding reduces risk . \",\n",
    "\n",
    "\" software engineering requires planning . \",\n",
    "\" version control uses git . \",\n",
    "\" commits track changes . \",\n",
    "\" branches isolate features . \",\n",
    "\" merges combine work . \",\n",
    "\" conflicts must be resolved . \",\n",
    "\" testing improves reliability . \",\n",
    "\" continuous integration automates checks . \",\n",
    "\" deployment releases software . \",\n",
    "\" maintenance keeps systems running . \"\n",
    "\"! ! ! ! ! ! ! ! !!  . . . . . . . . . . . . . . . . .12345678909876543234567 87 654321 234 56789 87 6543 23 4567 8\"\n",
    "\" 1234 2 3 56 7 6 32 36 8 8 6 323  ! ! !! ! ! ! ! !!  . . . . . . . .\"\n",
    "\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ! ! ! ! !! ! ! ! !! !  > > > >  .... . . . . . . . . . . . .  . . . . .. . . . . . \"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "merges = train_bpe(corpus, vocab_size=285)\n",
    "vocab = build_vocab(merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de0eaeb3-fe67-4579-b388-ac3ef2d8af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text,merge):\n",
    "\n",
    "    ids=[]\n",
    "    for part in find_special_pattern(text):\n",
    "        if part in SPECIAL_TOKENS:\n",
    "            ids.append(SPECIAL_TOKENS[part])\n",
    "        else:\n",
    "            for small_part in find_patterns(part):\n",
    "                token = list (small_part.encode(\"utf-8\"))\n",
    "            \n",
    "                while len (token)>=2:\n",
    "                    status=get_stats(token)\n",
    "                    pair=min(status,key = lambda p: merges.get(p,float('inf')))\n",
    "                    if pair not in merges:\n",
    "                        break\n",
    "                    num=merges[pair]\n",
    "                    token=merge_arr(token,pair,num)\n",
    "                    ids.extend(token)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bacd306d-ede2-485c-b9b4-d915d0b6f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids,vocab):\n",
    "    out=[]\n",
    "    for idx in ids:\n",
    "        if idx in Special_token_id:\n",
    "            out.append(Special_token_id[idx].encode(\"utf-8\"))\n",
    "        else:\n",
    "            out.append(vocab[idx])\n",
    "    return b\"\".join(out).decode(\"utf-8\", errors=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0d9fa1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100000, 32, 104, 101, 108, 281, 32, 119, 269, 108, 100, 100001]\n",
      "<|bos|> hello world<|eos|>\n"
     ]
    }
   ],
   "source": [
    "text = \"<|bos|> hello world  <|eos|>\"\n",
    "ids = encode(text, merges)\n",
    "print(ids)\n",
    "print(decode(ids, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946039c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffdb47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
